Aja como um arquiteto de software, desenvolvedor fullstack e engenheiro de IA. Sua tarefa √© criar um backend escal√°vel, seguro e leve, que atue como um orquestrador para an√°lise de documentos com aux√≠lio de modelos de linguagem locais (via Ollama).
üì• Requisitos Funcionais
Endpoint principal: POST /upload
Recebe um arquivo no body (ex: arquivo.pdf, arquivo.jpg, arquivo.png, arquivo.docx, arquivo.xlsx, etc.).
Recebe par√¢metros obrigat√≥rios no header:
Header	Descri√ß√£o
Prompt	Exemplo: "Verifique qual CNPJ existe nesse documento" (Obrigat√≥rio)
Format-Response	Exemplo: "[{\"CNPJ\": \"\"}]" (Obrigat√≥rio)
Example	Exemplo: "[{\"CNPJ\": \"XX.XXX.XXX/0001-XX\"}]" (Opcional)
Model	Exemplo: "gemma3:1b" (Obrigat√≥rio)
Key	Chave de autentica√ß√£o para uso da API. Deve ser validada com valor vindo do .env (Obrigat√≥rio)
üõ†Ô∏è Requisitos T√©cnicos
Instalar e rodar via Docker com base em imagem Ubuntu LTS.
Usar OCR (Tesseract) para imagens.
Usar PDF-to-Text, DOC/DOCX/Excel parser para documentos.
Enfileirar o processamento:
Fila para extra√ß√£o de texto (OCR ou parsing).
Fila para envio do prompt √† LLM local via Ollama.
Fila para formata√ß√£o e armazenamento da resposta.
Utilizar Ollama com modelo gemma3:1b (outros modelos podem ser usados futuramente).
Criar um sistema de filas para permitir processamento ass√≠ncrono e escal√°vel.
O backend deve:
Rodar em m√°quinas leves com modelos pequenos (ex: gemma3:1b).
Escalar em m√°quinas potentes, utilizando paraleliza√ß√£o inteligente baseada no hardware.
Banco de dados:
Usar MySQL ou SQLite (foco em leveza).
Persistir perguntas e respostas por at√© 1 hora (m√°ximo 24h).
Implementar limpeza autom√°tica para evitar ac√∫mulo de arquivos e logs.
üìä Endpoints adicionais
GET /queue
Retorna a lista de documentos na fila e seus status:
Upload realizado
Texto extra√≠do
Prompt processado
Erro (se houver)
GET /response/:id
Retorna a resposta da LLM para o documento espec√≠fico.
üìÅ Organiza√ß√£o do Projeto
O projeto dever√° incluir:
Dockerfile completo com todas depend√™ncias instaladas (Tesseract, Python libs, OCR tools, etc.).
Instala√ß√£o e configura√ß√£o do Ollama com o modelo gemma3:1b.
C√≥digo backend completo, pronto para rodar.
Endpoints REST documentados.
Scripts de inicializa√ß√£o.
Sistema de filas.
Valida√ß√£o de headers obrigat√≥rios.
Logs organizados e rotacionados.
üß™ Testes
Inclua exemplos de chamadas curl para teste.
Utilize o arquivo @teste.jpg presente na pasta como exemplo.
Forne√ßa tamb√©m uma collection do Postman com todos os endpoints prontos para uso.
üìÑ Documenta√ß√£o
Criar um README completo, contendo:
Instala√ß√£o passo a passo (Docker, depend√™ncias, env).
Como rodar a aplica√ß√£o.
Como testar.
Como escalar a aplica√ß√£o.
Como modificar o modelo Ollama.
Explica√ß√£o sobre cada endpoint e seus headers.
Estrat√©gia de limpeza autom√°tica dos dados.
üß† Considera√ß√µes sobre Escalabilidade
O sistema deve ser capaz de:
Rodar em m√°quinas modestas sem sobrecarga.
Escalar automaticamente (threads, workers, filas).
Paralelizar tarefas (extra√ß√£o, prompt, formata√ß√£o).
N√£o depender de servi√ßos externos al√©m da LLM local e banco leve.
üõ°Ô∏è Seguran√ßa
As requisi√ß√µes s√≥ ser√£o aceitas com Key v√°lida (armazenada no .env).
A aplica√ß√£o deve tratar falhas de upload, parsing, e resposta com mensagens claras.
Evitar upload de arquivos potencialmente maliciosos (limitar extens√µes permitidas).
Limitar tamanho dos arquivos para evitar sobrecarga.
üíª Ambiente
Ambiente atual:
Windows 11
Docker instalado
docker -v
Docker version 27.5.1, build 9f9e405
Conectado √† internet para baixar pacotes e imagens necess√°rias.