# üß† PROMPT PARA GERAR DOCUMENT OCR LLM API - SISTEMA COMPLETO

Aja como um arquiteto de software s√™nior, desenvolvedor fullstack experiente e especialista em IA. Sua tarefa √© criar um backend escal√°vel, seguro e altamente otimizado que atue como um **orquestrador inteligente** para an√°lise de documentos com aux√≠lio de modelos de linguagem locais (via Ollama).

## üì• ESPECIFICA√á√ïES FUNCIONAIS DETALHADAS

### üöÄ Endpoint Principal: POST /upload (Smart Upload)
**Funcionalidade**: Sistema de upload inteligente com detec√ß√£o autom√°tica de tipo de arquivo

**Headers Obrigat√≥rios**:
- `Key`: Chave de autentica√ß√£o (validada contra .env)
- `Prompt`: Pergunta/instru√ß√£o para o documento (ex: "Extraia o CNPJ deste documento")
- `Format-Response`: Formato esperado da resposta (ex: `[{"CNPJ": ""}]`)
- `Model`: Modelo Ollama a usar (ex: "gemma3:1b", "qwen2:0.5b")

**Headers Opcionais**:
- `Example`: Exemplo do formato esperado (ex: `[{"CNPJ": "XX.XXX.XXX/0001-XX"}]`)

**Sistema de Detec√ß√£o Autom√°tica**:
- `.jpg/.jpeg/.png` ‚Üí **Tesseract OCR** (pytesseract com lang='por+eng')
- `.pdf` ‚Üí **PyPDF2 Parser** (PyPDF2.PdfReader)
- `.docx/.doc` ‚Üí **python-docx Parser** (Document from python-docx)
- `.xlsx/.xls` ‚Üí **openpyxl Parser** (openpyxl.load_workbook)

**Fluxo de Processamento**:
1. Valida√ß√£o de arquivo (extens√£o, tamanho)
2. Detec√ß√£o autom√°tica do tipo e ferramenta
3. Cria√ß√£o de registro no banco SQLite
4. Trigger da cadeia de tarefas Celery
5. Retorno imediato do document_id

### üóÑÔ∏è Outros Endpoints Essenciais

#### GET /queue
- Lista todos os documentos e seus status
- Campos: id, filename, status, created_at, updated_at, completed_at, error_message
- Ordena√ß√£o por created_at DESC

#### GET /response/{document_id}
- Retorna resposta processada para documento espec√≠fico
- Inclui formatted_response, status e metadados

#### GET /health
- Health check b√°sico retornando status "OK"

#### POST /models/download
- Header: `Model-Name` (nome do modelo para download)
- Executa `ollama pull {model_name}` em subprocess
- Retorna progresso e status

#### GET /models/list
- Lista modelos Ollama instalados
- Executa `ollama list` e parseia sa√≠da

#### POST /config/compute + GET /config/compute
- Configura√ß√£o din√¢mica CPU/GPU para Ollama
- Valores: "cpu", "gpu", "auto"
- Persist√™ncia via arquivo de configura√ß√£o

## üèóÔ∏è ARQUITETURA T√âCNICA DETALHADA

### üì¶ Stack Tecnol√≥gico Completo
**Backend**: 
- FastAPI 0.104.1 (API REST com docs autom√°ticas)
- Uvicorn com standard (servidor ASGI)
- Python 3.10+ em Ubuntu 22.04

**Banco de Dados**:
- SQLAlchemy 1.4.53 (ORM)
- databases[sqlite] 0.8.0 (async operations)
- SQLite como banco principal

**Sistema de Filas**:
- Celery 5.3.4 (task queue)
- Redis 5.0.1 (broker + backend)
- Configura√ß√£o: worker_prefetch_multiplier=1, task_acks_late=True

**Processamento de Documentos**:
- pytesseract 0.3.10 + Pillow 10.1.0 (OCR)
- PyPDF2 3.0.1 (PDF parsing)
- python-docx 1.1.0 (Word documents)
- openpyxl 3.1.2 (Excel files)

**LLM Local**:
- Ollama (instala√ß√£o via curl script)
- httpx 0.25.2 para comunica√ß√£o async
- Timeout de 300s para requests

**Logging & Monitoramento**:
- loguru 0.7.2 (logs estruturados)
- Rota√ß√£o: 10MB (app.log), 5MB (verbose.log)
- Reten√ß√£o: 7 dias (app), 3 dias (verbose)

### üîÑ Cadeia de Processamento (3 Tarefas Celery)

#### 1. extract_text_task(document_id)
- L√™ documento do banco
- Chama extract_text_from_file() baseado no file_type
- Atualiza status para TEXT_EXTRACTED
- Dispara process_prompt_task()

#### 2. process_prompt_task(document_id)
- Cria prompt completo: "Context: {text}\n\nQuestion: {prompt}\n\n..."
- Chama Ollama via httpx async (POST /api/generate)
- Configura√ß√µes: stream=False, temperature=0.7, verbose=True
- Atualiza status para PROMPT_PROCESSED
- Dispara format_response_task()

#### 3. format_response_task(document_id)
- Aplica formata√ß√£o baseada em format_response
- Define completed_at timestamp
- Atualiza status para COMPLETED
- Finaliza processamento

**Tratamento de Erros**:
- Max 3 retries por tarefa
- Backoff exponencial: 60 * (2 ** retry_count)
- Status ERROR com error_message no banco

### üìä Modelo de Dados SQLAlchemy

```python
class DocumentStatus(enum.Enum):
    UPLOADED = "uploaded"
    TEXT_EXTRACTED = "text_extracted"
    PROMPT_PROCESSED = "prompt_processed"
    COMPLETED = "completed"
    ERROR = "error"

class Document(Base):
    __tablename__ = "documents"
    
    # IDs
    id = Column(Integer, primary_key=True, index=True)
    
    # Arquivo
    filename = Column(String(255), nullable=False)
    file_type = Column(String(50), nullable=False)
    file_path = Column(String(500), nullable=False)
    status = Column(Enum(DocumentStatus), default=DocumentStatus.UPLOADED)
    
    # Request
    prompt = Column(Text, nullable=False)
    format_response = Column(Text, nullable=False)
    example = Column(Text, nullable=True)
    model = Column(String(100), nullable=False)
    
    # Resultados
    extracted_text = Column(Text, nullable=True)
    llm_response = Column(Text, nullable=True)
    formatted_response = Column(Text, nullable=True)
    error_message = Column(Text, nullable=True)
    
    # Timestamps
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    completed_at = Column(DateTime(timezone=True), nullable=True)
```

## üê≥ CONTAINERIZA√á√ÉO COMPLETA

### Dockerfile Multi-Stage
```dockerfile
FROM ubuntu:22.04

# Deps sistema + Tesseract + Ollama
RUN apt-get update && apt-get install -y \
    python3 python3-pip python3-venv \
    tesseract-ocr tesseract-ocr-por libtesseract-dev \
    poppler-utils libpoppler-cpp-dev \
    curl wget git redis-server supervisor

# Instalar Ollama
RUN curl -fsSL https://ollama.ai/install.sh | sh

# App setup
WORKDIR /app
COPY requirements.txt .
RUN pip3 install --no-cache-dir -r requirements.txt
COPY . .
RUN mkdir -p /app/uploads /app/logs /app/temp
```

### Orquestra√ß√£o com Supervisor
**5 Processos Gerenciados**:
1. `redis-server` (queue broker)
2. `ollama serve` (LLM server na porta 11434)
3. `python3 main.py` (FastAPI na porta 8000)
4. `celery -A workers worker --concurrency=2` (processing workers)
5. `celery -A workers beat` (scheduler para cleanup)

### Docker Compose
```yaml
services:
  document-ocr-api:
    build: .
    ports:
      - "8000:8000"   # FastAPI
      - "11434:11434" # Ollama
      - "6379:6379"   # Redis
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
      - ./.env:/app/.env
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
```

## ‚öôÔ∏è CONFIGURA√á√ÉO AVAN√áADA

### Arquivo .env Completo
```bash
# API
API_KEY=your-super-secret-api-key-here
DEBUG=False
HOST=0.0.0.0
PORT=8000

# Database
DATABASE_URL=sqlite:///./documents.db

# Redis
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_MODEL=gemma3:1b

# Upload
MAX_FILE_SIZE=50
ALLOWED_EXTENSIONS=pdf,jpg,jpeg,png,docx,xlsx,xls,doc

# Cleanup
CLEANUP_INTERVAL_HOURS=1
MAX_RECORD_AGE_HOURS=24

# Logging
LOG_LEVEL=INFO
LOG_ROTATION=10MB
```

### Sistema de Limpeza Autom√°tica
- Tarefa Celery peri√≥dica (cleanup_task)
- Remove arquivos uploads/ mais antigos que MAX_RECORD_AGE_HOURS
- Remove registros do banco de dados antigos
- Limpa logs antigos baseado na rota√ß√£o

## üîí SEGURAN√áA E VALIDA√á√ïES

### Valida√ß√£o de Upload
- **Extens√µes**: Valida√ß√£o contra ALLOWED_EXTENSIONS
- **Tamanho**: M√°ximo MAX_FILE_SIZE (50MB default)
- **Tipo MIME**: Verifica√ß√£o adicional via python-magic (opcional)

### Autentica√ß√£o
- Header "Key" obrigat√≥rio em todos endpoints protegidos
- Dependency injection via FastAPI Depends(validate_api_key)
- HTTPException 401 para keys inv√°lidas

### Sanitiza√ß√£o
- UUIDs √∫nicos para nomes de arquivo
- Paths absolutos seguros para uploads/
- Escape de caracteres especiais em prompts

## üìä LOGGING E MONITORAMENTO

### Sistema de Logs Verbose
**Estrutura de Logs**:
- `app.log`: Logs gerais (rota√ß√£o 10MB, 7 dias)
- `verbose.log`: Logs detalhados (rota√ß√£o 5MB, 3 dias)
- Logs supervisor em `/var/log/supervisor/`

**Informa√ß√µes Logadas**:
- Detec√ß√£o autom√°tica de tipo de arquivo
- Ferramentas de extra√ß√£o utilizadas
- M√©tricas de processamento (tempo, tokens)
- Status de cada etapa da pipeline
- Erros detalhados com stack trace

### Health Checks
- FastAPI health endpoint (`/health`)
- Docker healthcheck com curl
- Verifica√ß√£o de servi√ßos (Redis, Ollama, Celery)

## üöÄ SCRIPTS DE INICIALIZA√á√ÉO

### start.sh (Script Principal)
```bash
#!/bin/bash
# Criar diret√≥rios
mkdir -p /var/log/supervisor /app/logs /app/uploads /app/temp

# Setup .env se n√£o existir
[ ! -f /app/.env ] && cp /app/.env.example /app/.env

# Iniciar Ollama temporariamente e baixar modelo
ollama serve &
sleep 10
ollama pull gemma3:1b

# Inicializar banco
python3 -c "from database import init_database_sync; init_database_sync()"

# Iniciar supervisor
exec /usr/bin/supervisord -c /etc/supervisor/conf.d/supervisord.conf
```

## üìù DOCUMENTA√á√ÉO E TESTES

### Collection Postman
- Criar collection completa com todos endpoints
- Environment com API_KEY e BASE_URL
- Exemplos de requests para cada tipo de arquivo
- Testes automatizados de status codes

### Scripts de Teste
```bash
# test_api.sh
curl -X POST "http://localhost:8000/upload" \
  -H "Key: myelin-ocr-llm-2024-super-secret-key" \
  -H "Prompt: Extraia o CNPJ deste documento" \
  -H "Format-Response: [{\"CNPJ\": \"\"}]" \
  -H "Model: gemma3:1b" \
  -F "file=@teste.jpg"
```

### README.md Completo
- Guia de instala√ß√£o passo a passo
- Exemplos de uso para cada tipo de arquivo
- Troubleshooting comum
- Configura√ß√µes avan√ßadas
- Escalabilidade e performance

## üéØ CARACTER√çSTICAS AVAN√áADAS

### Escalabilidade Inteligente
- Celery workers configur√°veis (--concurrency baseado em CPU)
- Sistema de filas Redis com persist√™ncia
- Timeout configur√°vel para LLM (300s default)
- Memory management para arquivos grandes

### Flexibilidade de Modelos
- Suporte a qualquer modelo Ollama
- Download din√¢mico via API
- Configura√ß√£o per-request via header Model
- Fallback para DEFAULT_MODEL

### Robustez
- Retry logic com backoff exponencial
- Circuit breaker para Ollama indispon√≠vel
- Graceful shutdown com cleanup
- Error handling detalhado

## üé® IMPLEMENTA√á√ÉO ESPEC√çFICA

### FastAPI com Async/Await
- Endpoints async para performance
- Database connections com databases library
- Exception handlers customizados
- Middleware para CORS se necess√°rio

### Celery Workers Otimizados
- Bind tasks para retry control
- Async loop para Ollama calls
- Database session management
- Memory cleanup p√≥s-processamento

### Utils Modulares
- Fun√ß√£o extract_text_from_file() com detec√ß√£o autom√°tica
- send_prompt_to_ollama() com retry e timeout
- format_llm_response() extens√≠vel
- cleanup_old_files() com configura√ß√£o flex√≠vel

## üö® PONTOS CR√çTICOS DE IMPLEMENTA√á√ÉO

1. **Inicializa√ß√£o Completa**: O sistema deve funcionar imediatamente ap√≥s `docker-compose up --build`
2. **Detec√ß√£o Autom√°tica**: Logs verbose mostrando qual ferramenta foi escolhida
3. **Cadeia de Tarefas**: Cada task deve disparar a pr√≥xima automaticamente
4. **Error Handling**: Falhas em qualquer etapa devem ser capturadas e logadas
5. **Performance**: Sistema deve ser responsivo mesmo com arquivos grandes
6. **Cleanup**: Limpeza autom√°tica deve funcionar sem interven√ß√£o manual

## üìã CHECKLIST DE ENTREGA

- [ ] FastAPI funcionando na porta 8000
- [ ] Ollama rodando na porta 11434
- [ ] Redis funcionando na porta 6379
- [ ] Todos os 5 processos no supervisor
- [ ] Sistema de upload com detec√ß√£o autom√°tica
- [ ] Cadeia completa de 3 tarefas Celery
- [ ] Banco SQLite com modelo completo
- [ ] Logs verbose detalhados
- [ ] Cleanup autom√°tico funcionando
- [ ] Health checks operacionais
- [ ] Collection Postman funcional
- [ ] README com instru√ß√µes completas
- [ ] Scripts de in√≠cio r√°pido
- [ ] Tratamento de erros robusto

**OBJETIVO FINAL**: Sistema completamente funcional, pronto para produ√ß√£o, que processe qualquer tipo de documento suportado de forma autom√°tica e inteligente, com monitoramento completo e capacidade de escalar conforme a demanda.