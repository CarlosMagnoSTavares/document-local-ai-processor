# ğŸ§  Document OCR LLM API

API escalÃ¡vel, segura e leve para anÃ¡lise de documentos com auxÃ­lio de modelos de linguagem locais (Ollama).

## ğŸ†• Novidades v1.2 (Smart Upload & ConfiguraÃ§Ã£o AvanÃ§ada)
- âœ… **ğŸš€ SMART UPLOAD**: DetecÃ§Ã£o automÃ¡tica de tipo de arquivo e ferramenta
- âœ… **âš™ï¸ ConfiguraÃ§Ã£o CPU/GPU**: Alterne entre CPU e GPU para Ollama
- âœ… **ğŸ”„ PersistÃªncia**: ConfiguraÃ§Ãµes salvas automaticamente
- âœ… **ğŸ“Š Logs Verbosos**: Mostra detecÃ§Ã£o automÃ¡tica e modo de processamento
- âœ… **ğŸ¤– Gerenciamento de Modelos**: Download e listagem via API
- âœ… **ğŸ› ï¸ Auto-detecÃ§Ã£o**: JPGâ†’OCR, PDFâ†’Parser, DOCXâ†’Parser, etc. 

## ğŸ“‹ Ãndice

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Arquitetura](#-arquitetura)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [ConfiguraÃ§Ã£o](#-configuraÃ§Ã£o)
- [Como Usar](#-como-usar)
- [Endpoints](#-endpoints)
- [Teste](#-teste)
- [Escalabilidade](#-escalabilidade)
- [SeguranÃ§a](#-seguranÃ§a)
- [Monitoramento](#-monitoramento)
- [Troubleshooting](#-troubleshooting)

## ğŸš€ CaracterÃ­sticas

- **ğŸš€ Smart Upload**: DetecÃ§Ã£o automÃ¡tica de tipo de arquivo e ferramenta apropriada
- **âš™ï¸ ConfiguraÃ§Ã£o CPU/GPU**: Controle dinÃ¢mico do modo de processamento Ollama  
- **OCR AvanÃ§ado**: Tesseract para extraÃ§Ã£o de texto de imagens (JPG, PNG)
- **Parsers MÃºltiplos**: PDF, DOCX, XLSX com detecÃ§Ã£o automÃ¡tica
- **LLM Local**: IntegraÃ§Ã£o com Ollama (qualquer modelo suportado)
- **Gerenciamento de Modelos**: Download e listagem via API
- **Sistema de Filas**: Processamento assÃ­ncrono com Celery + Redis
- **Modo Verbose**: Logs detalhados mostrando detecÃ§Ã£o automÃ¡tica
- **Auto-Limpeza**: RemoÃ§Ã£o automÃ¡tica de arquivos e dados antigos
- **Containerizado**: Docker com todas as dependÃªncias
- **EscalÃ¡vel**: Suporte a paralelizaÃ§Ã£o baseada no hardware
- **Monitoramento**: Logs estruturados e health checks avanÃ§ados

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI       â”‚    â”‚   Celery        â”‚    â”‚   Ollama        â”‚
â”‚   (API Server)  â”‚â”€â”€â”€â”€â”‚   (Workers)     â”‚â”€â”€â”€â”€â”‚   (LLM)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SQLite        â”‚    â”‚   Redis         â”‚    â”‚   Tesseract     â”‚
â”‚   (Database)    â”‚    â”‚   (Queue)       â”‚    â”‚   (OCR)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo de Processamento

1. **Upload**: Cliente envia arquivo + headers obrigatÃ³rios
2. **ValidaÃ§Ã£o**: VerificaÃ§Ã£o de API key, tipo e tamanho do arquivo
3. **Fila de ExtraÃ§Ã£o**: Worker extrai texto (OCR/Parser)
4. **Fila de LLM**: Worker envia prompt para Ollama
5. **Fila de FormataÃ§Ã£o**: Worker formata resposta final
6. **Resposta**: Cliente consulta resultado via API

## ğŸ› ï¸ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Docker 20.0+
- Docker Compose 2.0+
- 4GB+ RAM (recomendado 8GB+)
- 10GB+ espaÃ§o em disco

### InstalaÃ§Ã£o via Docker

1. **Clone o repositÃ³rio**
```bash
git clone <repository-url>
cd MYELIN-OCR-LLM-LOCAL
```

2. **Configure o ambiente**
```bash
cp .env.example .env
# Edite o .env com suas configuraÃ§Ãµes
```

3. **Construa e execute o container**
```bash
# OpÃ§Ã£o 1: Docker Compose (recomendado)
docker-compose up --build

# OpÃ§Ã£o 2: Docker direto
docker build -t document-ocr-api .
docker run -p 8000:8000 -p 11434:11434 -v $(pwd)/uploads:/app/uploads document-ocr-api
```

4. **Aguarde a inicializaÃ§Ã£o**
```bash
# Verificar se estÃ¡ funcionando
curl http://localhost:8000/health
```

**Tempo de inicializaÃ§Ã£o**: ~5-10 minutos (download do modelo gemma3:1b)

## âš™ï¸ ConfiguraÃ§Ã£o

### Arquivo .env

```bash
# API Configuration
API_KEY=myelin-ocr-llm-2024-super-secret-key
DEBUG=False
HOST=0.0.0.0
PORT=8000

# Database Configuration
DATABASE_URL=sqlite:///./documents.db

# Redis Configuration
REDIS_URL=redis://localhost:6379/0

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_MODEL=gemma3:1b

# File Upload Configuration
MAX_FILE_SIZE=50
ALLOWED_EXTENSIONS=pdf,jpg,jpeg,png,docx,xlsx,xls,doc

# Queue Configuration
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Cleanup Configuration
CLEANUP_INTERVAL_HOURS=1
MAX_RECORD_AGE_HOURS=24

# Logging Configuration
LOG_LEVEL=INFO
LOG_ROTATION=10MB
```

### Modificar Modelo Ollama

```bash
# Entrar no container
docker exec -it <container_name> bash

# Listar modelos disponÃ­veis
ollama list

# Instalar novo modelo
ollama pull llama2:7b

# Atualizar .env
# DEFAULT_MODEL=llama2:7b
```

## ğŸ“– Como Usar

### 1. ğŸš€ Smart Upload (DetecÃ§Ã£o AutomÃ¡tica)

```bash
# O sistema detecta automaticamente que Ã© uma imagem e usa OCR
curl -X POST "http://localhost:8000/upload" \
  -H "Key: myelin-ocr-llm-2024-super-secret-key" \
  -H "Prompt: Verifique qual CNPJ existe nesse documento" \
  -H "Format-Response: [{\"CNPJ\": \"\"}]" \
  -H "Model: gemma3:1b" \
  -F "file=@teste.jpg"

# Para PDF - detecta automaticamente e usa parser PDF
curl -X POST "http://localhost:8000/upload" \
  -H "Key: myelin-ocr-llm-2024-super-secret-key" \
  -H "Prompt: Extraia dados pessoais deste documento" \
  -H "Format-Response: [{\"nome\": \"\", \"cpf\": \"\"}]" \
  -H "Model: gemma3:1b" \
  -F "file=@documento.pdf"
```

**ğŸ› ï¸ DetecÃ§Ã£o AutomÃ¡tica:**
- `.jpg/.png` â†’ Tesseract OCR
- `.pdf` â†’ PyPDF2 Parser  
- `.docx` â†’ python-docx Parser
- `.xlsx` â†’ openpyxl Parser

**Resposta:**
```json
{
  "status": "success",
  "message": "Document uploaded and processing started",
  "document_id": 1,
  "filename": "teste.jpg"
}
```

### 2. Verificar Status da Fila

```bash
curl -H "Key: myelin-ocr-llm-2024-super-secret-key" "http://localhost:8000/queue"
```

### 3. Obter Resposta

```bash
curl -H "Key: myelin-ocr-llm-2024-super-secret-key" "http://localhost:8000/response/1"
```

### 4. Gerenciamento de Modelos (NOVO!)

#### Listar Modelos DisponÃ­veis
```bash
curl -H "Key: myelin-ocr-llm-2024-super-secret-key" "http://localhost:8000/models/list"
```

**Resposta:**
```json
{
  "status": "success",
  "models": [
    {"name": "gemma3:1b", "status": "available"},
    {"name": "llama3:8b", "status": "available"}
  ],
  "total_models": 2
}
```

#### Baixar Novo Modelo
```bash
curl -X POST "http://localhost:8000/models/download" \
  -H "Key: myelin-ocr-llm-2024-super-secret-key" \
  -H "Model-Name: llama3:8b"
```

**ğŸ¤– Modelos VÃ¡lidos e Recomendados:**
- **LLaMA 3 (Meta)**: `llama3:8b`, `llama3:70b`
- **Gemma 2 (Google)**: `gemma2:2b`, `gemma2:9b`, `gemma2:27b` 
- **Mistral AI**: `mistral:7b`, `mistral:instruct`
- **Qwen 2 (Alibaba)**: `qwen2:0.5b`, `qwen2:1.5b`, `qwen2:7b`
- **Phi-3 (Microsoft)**: `phi3:mini`, `phi3:medium`

ğŸ’¡ **RecomendaÃ§Ãµes de uso:**
- `qwen2:0.5b` - Mais rÃ¡pido (500MB)
- `gemma2:2b` - Equilibrado (1.6GB)  
- `llama3:8b` - Mais preciso (4.7GB)

âš ï¸ **Importante**: Download pode levar 5-30 minutos dependendo do modelo

### 5. âš™ï¸ ConfiguraÃ§Ã£o CPU/GPU (NOVO!)

#### Verificar Modo Atual
```bash
curl -H "Key: myelin-ocr-llm-2024-super-secret-key" "http://localhost:8000/config/compute"
```

**Resposta:**
```json
{
  "status": "success",
  "compute_mode": "cpu",
  "gpu_enabled": false,
  "cuda_devices": "",
  "config": {
    "OLLAMA_COMPUTE_MODE": "cpu",
    "OLLAMA_GPU_ENABLED": "0",
    "CUDA_VISIBLE_DEVICES": ""
  }
}
```

#### Alternar para GPU (Mais RÃ¡pido)
```bash
curl -X POST "http://localhost:8000/config/compute" \
  -H "Key: myelin-ocr-llm-2024-super-secret-key" \
  -H "Compute-Mode: gpu"
```

#### Alternar para CPU (EconÃ´mico)
```bash
curl -X POST "http://localhost:8000/config/compute" \
  -H "Key: myelin-ocr-llm-2024-super-secret-key" \
  -H "Compute-Mode: cpu"
```

**ğŸ”„ ConfiguraÃ§Ã£o Persistente:** As configuraÃ§Ãµes sÃ£o salvas no `.env` e aplicadas automaticamente.

### 6. Usando Modelos Diferentes

```bash
# Upload com LLaMA3:8b (mais preciso)
curl -X POST "http://localhost:8000/upload" \
  -H "Key: myelin-ocr-llm-2024-super-secret-key" \
  -H "Prompt: AnÃ¡lise detalhada deste documento" \
  -H "Format-Response: [{\"anÃ¡lise\": \"\", \"detalhes\": \"\"}]" \
  -H "Model: llama3:8b" \
  -F "file=@documento.pdf"
```

## ğŸ”— Endpoints

| MÃ©todo | Endpoint | DescriÃ§Ã£o | Headers ObrigatÃ³rios |
|--------|----------|-----------|---------------------|
| `POST` | `/upload` | ğŸš€ **SMART UPLOAD** - Auto-detecÃ§Ã£o | Key, Prompt, Format-Response, Model |
| `GET` | `/queue` | Status da fila | Key |
| `GET` | `/response/{id}` | Resposta do documento | Key |
| `POST` | `/models/download` | Download de modelo | Key, Model-Name |
| `GET` | `/models/list` | Lista modelos | Key |
| `POST` | `/config/compute` | **ğŸ†• NOVO** - Configurar CPU/GPU | Key, Compute-Mode |
| `GET` | `/config/compute` | **ğŸ†• NOVO** - Ver modo atual | Key |
| `GET` | `/health` | Health check | - |
| `GET` | `/` | InformaÃ§Ãµes da API | - |

### Headers ObrigatÃ³rios

| Header | Exemplo | DescriÃ§Ã£o |
|--------|---------|-----------|
| `Key` | `myelin-ocr-llm-2024-super-secret-key` | Chave de autenticaÃ§Ã£o |
| `Prompt` | `"Extraia o CNPJ"` | Pergunta sobre o documento |
| `Format-Response` | `[{"CNPJ": ""}]` | Formato esperado da resposta |
| `Model` | `gemma3:1b` | Modelo Ollama a usar |
| `Example` | `[{"CNPJ": "12.345.678/0001-90"}]` | Exemplo de resposta (opcional) |

### Status de Processamento

- `uploaded`: Arquivo recebido
- `text_extracted`: Texto extraÃ­do com sucesso
- `prompt_processed`: LLM processou o prompt
- `completed`: Processamento finalizado
- `error`: Erro durante processamento

## ğŸ§ª Teste

### Script de Teste Automatizado

```bash
# Windows
test_api.bat

# Linux/Mac
chmod +x test_api.sh
./test_api.sh
```

### Collection do Postman

1. **Importe os arquivos no Postman:**
   - `postman_collection.json` (Collection)
   - `postman_environment.json` (Environment)

2. **Configure o ambiente** "Document OCR LLM API - Local"

3. **Como usar:**
   - Execute "Health Check" primeiro
   - Execute "Upload Document (Image)" com arquivo `teste.jpg`
   - O `document_id` serÃ¡ preenchido automaticamente
   - Execute "Get Queue Status" para acompanhar
   - Execute "Get Document Response" para o resultado

### Testes Manuais

```bash
# 1. Health Check
curl http://localhost:8000/health

# 2. Upload com teste.jpg
curl -X POST "http://localhost:8000/upload" \
  -H "Key: myelin-ocr-llm-2024-super-secret-key" \
  -H "Prompt: Descreva o que vocÃª vÃª na imagem" \
  -H "Format-Response: {\"descricao\": \"\"}" \
  -H "Model: gemma3:1b" \
  -F "file=@teste.jpg"

# 3. Verificar status
curl -H "Key: myelin-ocr-llm-2024-super-secret-key" \
  "http://localhost:8000/queue"
```

## ğŸ“ˆ Escalabilidade

### ConfiguraÃ§Ã£o para MÃ¡quinas Modestas

```bash
# No .env
CELERY_WORKERS=1
CELERY_CONCURRENCY=1
MODEL=gemma3:1b
```

### ConfiguraÃ§Ã£o para MÃ¡quinas Potentes

```bash
# No .env
CELERY_WORKERS=4
CELERY_CONCURRENCY=4
MODEL=llama2:7b
```

### Escalonamento Manual

```bash
# Adicionar mais workers
docker exec -d <container> celery -A workers worker --concurrency=4

# Monitorar workers
docker exec <container> celery -A workers inspect active
```

## ğŸ”’ SeguranÃ§a

### ValidaÃ§Ãµes Implementadas

- âœ… AutenticaÃ§Ã£o via API Key
- âœ… ValidaÃ§Ã£o de tipos de arquivo
- âœ… LimitaÃ§Ã£o de tamanho de arquivo
- âœ… SanitizaÃ§Ã£o de inputs
- âœ… Rate limiting (via Celery)

### ConfiguraÃ§Ãµes de SeguranÃ§a

```bash
# Tipos de arquivo permitidos
ALLOWED_EXTENSIONS=pdf,jpg,jpeg,png,docx,xlsx

# Tamanho mÃ¡ximo
MAX_FILE_SIZE=50

# API Key forte
API_KEY=myelin-ocr-llm-2024-super-secret-key
```

## ğŸ“Š Monitoramento (Modo Verbose Ativo!)

### Logs Detalhados em Tempo Real

O sistema agora opera em **modo verbose** com logs detalhados de todo o processo:

```bash
# Ver logs em tempo real do container
docker logs <container_name> -f

# Logs especÃ­ficos por serviÃ§o (com modo verbose)
docker exec -it <container_name> tail -f /var/log/supervisor/fastapi.log     # FastAPI verbose
docker exec -it <container_name> tail -f /var/log/supervisor/celery_worker.log  # Celery debug
docker exec -it <container_name> tail -f /var/log/supervisor/ollama.log        # Ollama verbose

# Logs da aplicaÃ§Ã£o (dentro do container)
docker exec -it <container_name> tail -f /app/logs/app.log        # Logs gerais
docker exec -it <container_name> tail -f /app/logs/verbose.log    # Logs verbose especÃ­ficos
```

### ğŸ“‹ O que vocÃª verÃ¡ nos logs verbose:

#### ğŸ“¤ **Smart Upload Process**
```
ğŸ“¤ VERBOSE: Starting document upload process
ğŸ“ VERBOSE: Filename: teste.jpg
ğŸ¤– VERBOSE: Model requested: gemma3:1b
ğŸ“ VERBOSE: File size: 2.45 MB
ğŸ” VERBOSE: Auto-detected file type: JPG
ğŸ› ï¸ VERBOSE: Will use extraction tool: Tesseract OCR
ğŸ’¾ VERBOSE: Saving file to disk...
âœ… VERBOSE: File saved to: uploads/uuid_teste.jpg
ğŸ—„ï¸ VERBOSE: Creating database record...
ğŸš€ VERBOSE: Starting Celery task for document 123
```

#### ğŸ” **OCR Process**
```
ğŸ” VERBOSE: Starting text extraction from JPG file: uploads/uuid_teste.jpg
ğŸ–¼ï¸ VERBOSE: Using OCR (Tesseract) for image processing
âœ… VERBOSE: Text extraction completed. Extracted 847 characters
ğŸ“„ VERBOSE: Text preview: NOTA FISCAL ELETRÃ”NICA...
```

#### ğŸ¤– **LLM Process**
```
ğŸ¤– VERBOSE: Sending prompt to Ollama model 'gemma3:1b'
ğŸ“„ VERBOSE: Context length: 847 characters
â“ VERBOSE: Prompt: Verifique qual CNPJ existe nesse documento
ğŸ”— VERBOSE: Making request to http://localhost:11434/api/generate
âœ… VERBOSE: Ollama response received (234 chars)
ğŸ’¬ VERBOSE: Response preview: O CNPJ encontrado no documento Ã©...
â±ï¸ VERBOSE: Total duration: 3.45s
ğŸ”¢ VERBOSE: Prompt tokens: 298
ğŸ“Š VERBOSE: Response tokens: 87
```

#### âš™ï¸ **CPU/GPU Configuration**
```
ğŸ”„ VERBOSE: Switching Ollama compute mode to: GPU
ğŸš€ VERBOSE: GPU mode enabled - CUDA devices accessible
ğŸ”„ VERBOSE: Restarting Ollama service with GPU mode...
âœ… VERBOSE: Ollama restarted successfully in GPU mode
â„¹ï¸ VERBOSE: Current compute mode: GPU
```

### Logs Tradicionais

### Health Checks

```bash
# API Health
curl http://localhost:8000/health

# Ollama Health
curl http://localhost:11434/api/tags

# Redis Health
docker exec <container> redis-cli ping
```

### MÃ©tricas

```bash
# Status dos workers
docker exec <container> celery -A workers inspect stats

# Fila de tarefas
docker exec <container> celery -A workers inspect reserved

# Uso de recursos
docker stats <container_name>
```

## ğŸ”§ Troubleshooting

### Problemas Comuns

#### 1. Container nÃ£o inicia
```bash
# Verificar logs
docker logs <container_name>

# Verificar portas
netstat -tulpn | grep :8000
```

#### 2. Ollama nÃ£o responde
```bash
# Verificar se o modelo foi baixado
docker exec <container> ollama list

# Baixar modelo manualmente
docker exec <container> ollama pull gemma3:1b
```

#### 3. Workers nÃ£o processam
```bash
# Verificar Redis
docker exec <container> redis-cli ping

# Reiniciar workers
docker exec <container> supervisorctl restart celery_worker
```

#### 4. Erro de OCR
```bash
# Verificar Tesseract
docker exec <container> tesseract --version

# Testar OCR
docker exec <container> tesseract /app/teste.jpg stdout -l por
```

### Limpeza Manual

```bash
# Limpar arquivos antigos
docker exec <container> python3 -c "from utils import cleanup_old_files; cleanup_old_files()"

# Limpar banco de dados
docker exec <container> python3 -c "
from database import SessionLocal
from models import Document
from datetime import datetime, timedelta
db = SessionLocal()
cutoff = datetime.utcnow() - timedelta(hours=1)
deleted = db.query(Document).filter(Document.created_at < cutoff).delete()
db.commit()
print(f'Deleted {deleted} records')
"
```

## ğŸš€ URLs Importantes

- **API Principal**: http://localhost:8000
- **DocumentaÃ§Ã£o**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health
- **Ollama**: http://localhost:11434

## ğŸ“„ Arquivos de ConfiguraÃ§Ã£o

- `build_and_run.bat` - Script de build para Windows
- `test_api.bat` - Script de teste para Windows
- `postman_collection.json` - Collection do Postman
- `postman_environment.json` - Environment do Postman
- `.env` - ConfiguraÃ§Ãµes da aplicaÃ§Ã£o
- `docker-compose.yml` - OrquestraÃ§Ã£o de containers

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a **GNU Affero General Public License v3.0 (AGPL-3.0)**.

### ğŸ†“ Uso Livre Permitido
- âœ… **Uso pessoal e educacional**
- âœ… **Pesquisa e desenvolvimento**
- âœ… **Projetos open source** (devem tambÃ©m usar licenÃ§a compatÃ­vel)
- âœ… **ContribuiÃ§Ãµes** para este projeto

### ğŸ¢ Uso Comercial
Para **uso comercial**, incluindo:
- ğŸ’¼ IntegraÃ§Ã£o em produtos comerciais
- ğŸŒ Oferecimento como serviÃ§o (SaaS)
- ğŸ’° Venda ou distribuiÃ§Ã£o comercial
- ğŸ­ Uso em ambiente empresarial com fins lucrativos

**Ã‰ necessÃ¡ria uma licenÃ§a comercial separada.** Entre em contato:

ğŸ“§ **Email**: license@myelin-ai.com  
ğŸ’¬ **LinkedIn**: [Seu Perfil LinkedIn]  
ğŸ“„ **Termos**: NegociÃ¡veis conforme o caso de uso

### âš–ï¸ Compliance AGPL
Ao usar este software sob AGPL-3.0, vocÃª deve:
- ğŸ“– **Manter avisos de copyright** em todos os arquivos
- ğŸ”“ **Disponibilizar cÃ³digo fonte** de qualquer modificaÃ§Ã£o
- ğŸ“‹ **Usar licenÃ§a compatÃ­vel** em projetos derivados
- ğŸŒ **Fornecer cÃ³digo fonte** mesmo para uso como serviÃ§o web

### ğŸ“‹ LicenÃ§as de Terceiros
Este projeto utiliza bibliotecas open source com suas respectivas licenÃ§as:
- **FastAPI**: MIT License
- **Tesseract OCR**: Apache 2.0 License  
- **Ollama**: MIT License
- **PostgreSQL**: PostgreSQL License
- **Redis**: BSD License

Para mais detalhes, consulte o arquivo [LICENSE](LICENSE).

### ğŸ¤ ContribuiÃ§Ãµes
ContribuiÃ§Ãµes sÃ£o bem-vindas! Ao contribuir, vocÃª concorda que suas contribuiÃ§Ãµes serÃ£o licenciadas sob os mesmos termos deste projeto.

Para contribuir:
1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

---

ğŸ¯ **Pronto para usar!** O sistema estÃ¡ configurado para rodar em mÃ¡quinas modestas e escalar conforme necessÃ¡rio.

ğŸ“œ **Licenciado sob AGPL-3.0** - Uso livre para projetos compatÃ­veis, licenÃ§a comercial para uso empresarial. 